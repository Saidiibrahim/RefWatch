---
task_id: 06
plan_id: openai_responses_migration
plan_file: ../plans/PLAN_openai_responses_migration.md
title: Document migration and clean up old code
phase: Phase 6 - Documentation & Cleanup
created: 2025-10-09
status: Completed
priority: Medium
estimated_minutes: 60
dependencies: [TASK_05_openai_responses_validation_and_docs.md]
tags: [documentation, cleanup, refactoring]
---

## Objective
Update code documentation, add migration notes, and clean up deprecated Chat Completions code while preserving project history and learnings.

## Documentation Updates

### 1. Inline Code Comments
Update `OpenAIAssistantService.swift` with comprehensive comments:

```swift
/// Streams responses from OpenAI's Responses API.
///
/// This service uses the modern Responses API (`POST /v1/responses`) instead of
/// the legacy Chat Completions API. Key differences:
/// - System prompt sent via `instructions` field (not as first message)
/// - Request uses `input` array (not `messages`)
/// - SSE events use `response.output_text.delta` format
///
/// Reference: https://platform.openai.com/docs/api-reference/responses/create
final class OpenAIAssistantService: AssistantProviding {
    // ...

    /// Builds a Responses API payload from chat history.
    ///
    /// Maps the internal `ChatMessage` format to OpenAI's Responses API structure:
    /// - System prompt â†’ `instructions` field
    /// - Message history â†’ `input` array (user/assistant roles only)
    ///
    /// - Parameters:
    ///   - model: Model identifier (e.g., "gpt-4o-mini")
    ///   - systemPrompt: Instructions for the AI assistant
    ///   - messages: Conversation history
    /// - Returns: JSON-serializable payload dictionary
    private static func buildResponsesPayload(
        model: String,
        systemPrompt: String,
        messages: [ChatMessage]
    ) -> [String: Any] {
        // Implementation...
    }

    /// Parses Server-Sent Events from the Responses API stream.
    ///
    /// The Responses API uses a structured SSE format:
    /// ```
    /// event: response.output_text.delta
    /// data: {"delta":"Hello","item_id":"msg_007"}
    ///
    /// event: response.done
    /// data: {"type":"response.done"}
    /// ```
    ///
    /// - Parameters:
    ///   - line: Raw SSE line from the stream
    ///   - currentEvent: In-progress event being assembled
    /// - Returns: Completed event, or nil if still building
    private static func parseSSELine(
        _ line: String,
        currentEvent: inout SSEEvent?
    ) -> SSEEvent? {
        // Implementation...
    }
}
```

### 2. Migration Notes Document
Create inline comment block documenting the migration:

```swift
// MARK: - Migration Notes
//
// This service was migrated from Chat Completions API to Responses API on 2025-10-09.
//
// **Why migrate?**
// - Future-ready for advanced features (tool calling, multimodal, reasoning)
// - Cleaner API design (system prompt separate from conversation)
// - Better error reporting and usage statistics
//
// **Key changes:**
// 1. Endpoint: /v1/chat/completions â†’ /v1/responses
// 2. Request: messages â†’ input, system message â†’ instructions field
// 3. SSE events: choices[].delta.content â†’ response.output_text.delta
//
// **Backward compatibility:**
// - AssistantProviding interface unchanged
// - StubAssistantService still works for DEBUG builds
// - No breaking changes to client code
//
// **Related documentation:**
// - Plan: .agent/plans/PLAN_openai_responses_migration.md
// - Tasks: .agent/tasks/TASK_*_openai_responses_*.md
```

### 3. API Reference Comments
Add references to OpenAI documentation:

```swift
// OpenAI Responses API documentation:
// https://platform.openai.com/docs/api-reference/responses/create
//
// Streaming events reference:
// https://platform.openai.com/docs/guides/streaming-responses
//
// Input format reference:
// https://platform.openai.com/docs/api-reference/responses/input-items
```

## Code Cleanup

### 1. Remove Deprecated Code
Remove old Chat Completions parsing logic:

```swift
// DELETE:
private struct ChatStreamChunk: Decodable {
    struct Choice: Decodable { let delta: Delta? }
    struct Delta: Decodable { let content: String? }
    let choices: [Choice]
}

private static func parseDelta(from data: Data) -> String? {
    guard let chunk = try? JSONDecoder().decode(ChatStreamChunk.self, from: data) else { return nil }
    return chunk.choices.first?.delta?.content
}
```

### 2. Consolidate Helper Methods
Group related methods:

```swift
// MARK: - Request Building
private static func buildResponsesPayload(...) { }
private static func buildInputArray(...) { }

// MARK: - SSE Parsing
private static func parseSSELine(...) { }
private static func handleResponseEvent(...) { }

// MARK: - Utilities
private static func makeRequest(...) { }
```

### 3. Update File Header
Ensure file header reflects current state:

```swift
//
//  OpenAIAssistantService.swift
//  RefZoneiOS
//
//  Uses OpenAI's Responses API for streaming chat completions.
//  Migrated from Chat Completions API on 2025-10-09.
//
```

## README Updates (if applicable)
If there's a README or developer documentation:

1. Update API endpoint references
2. Add section on OpenAI integration
3. Document required secrets (`OPENAI_API_KEY`)
4. Note DEBUG-only feature flag

## Git Commit Message Template
```
refactor(ios): migrate to OpenAI Responses API

- Replace Chat Completions endpoint with Responses API
- Update request format (messages â†’ input, instructions field)
- Redesign SSE parser for Responses API events
- Add structured error handling and DEBUG logging
- Maintain backward compatibility with existing interface

Benefits:
- Future-ready for tool calling and multimodal features
- Cleaner separation of system prompt from conversation
- Better error reporting and usage statistics

Technical changes:
- Endpoint: /v1/chat/completions â†’ /v1/responses
- SSE format: choices[].delta â†’ response.output_text.delta
- Payload: messages array â†’ input array + instructions

Testing:
- Unit tests for request builder and SSE parser
- Manual testing confirms no regressions
- StubAssistantService still works for DEBUG builds

Refs: .agent/plans/PLAN_openai_responses_migration.md

ðŸ¤– Generated with [Claude Code](https://claude.com/claude-code)

Co-Authored-By: Claude <noreply@anthropic.com>
```

## Code Quality Checklist
âœ… SwiftLint compliance (if used)
âœ… No compiler warnings
âœ… All TODOs addressed or tracked
âœ… Consistent code style
âœ… Proper access control (private/internal)

## Deliverables
1. Comprehensive inline documentation
2. Migration notes in code
3. Deprecated code removed
4. Code organized into logical sections
5. README updated (if applicable)
6. Clean git commit ready

## Acceptance Criteria
âœ… All public APIs documented
âœ… Migration history preserved in comments
âœ… OpenAI documentation URLs referenced
âœ… Old Chat Completions code removed
âœ… Code passes linting/formatting checks
âœ… Git commit message follows conventions
âœ… No breaking changes to public interface

---

## Documentation Notes (2025-10-10)
- Updated `OpenAIAssistantService.swift` header comment to record the migration date and reference the Responses API.
- Added inline links to the official Responses API create, streaming, and input item docs directly above the streaming pipeline implementation.
- Captured design/implementation details across TASK_01â€“TASK_05 files to provide a written audit trail for the migration decisions.
- README changes were not required for this slice; secrets handling and feature flags remain accurate.
